{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runpod: HF → Canary (NeMo) — PyTorch 2.8 / CUDA 12.8\n",
    "\n",
    "Блокнот для Runpod / PyTorch 2.8 / CUDA 12.8. Без Parquet: экспорт WAV 16 kHz mono + JSONL. Исправлен импорт NeMo: перед установкой/импортом nemo_toolkit[asr] выравниваем NumPy/SciPy/Lightning/TorchMetrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка окружения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, platform\n",
    "import torch\n",
    "\n",
    "print(\"Python :\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Torch  :\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA visible:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "try:\n",
    "    subprocess.run([\"nvidia-smi\"], check=True)\n",
    "except Exception as e:\n",
    "    print(\"[WARN] nvidia-smi not available:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конфиг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, re\n",
    "\n",
    "# --- Ключ HF: вставь в переменные окружения контейнера ---\n",
    "# os.environ[\"HF_TOKEN\"] = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "# os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = os.environ.get(\"HF_TOKEN\",\"\")\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "DATA_DIR    = ROOT / \"data_wav\"\n",
    "OUT_DIR     = ROOT / \"filtered_datasets\"\n",
    "TMP_DIR     = ROOT / \".tmp\"\n",
    "HF_HOME_DIR = ROOT / \".hf\"\n",
    "\n",
    "for d in [DATA_DIR, OUT_DIR, TMP_DIR, HF_HOME_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ.setdefault(\"HF_HOME\", str(HF_HOME_DIR))\n",
    "os.environ.setdefault(\"HF_HUB_CACHE\", str(HF_HOME_DIR / \"hub\"))\n",
    "os.environ.setdefault(\"TRANSFORMERS_CACHE\", str(HF_HOME_DIR / \"transformers\"))\n",
    "os.environ.setdefault(\"TMP\", str(TMP_DIR))\n",
    "os.environ.setdefault(\"TEMP\", str(TMP_DIR))\n",
    "\n",
    "MODEL_ID    = \"nvidia/canary-1b-v2\"\n",
    "NEMO_PATH   = None\n",
    "SOURCE_LANG = \"ru\"\n",
    "TARGET_LANG = \"ru\"\n",
    "TASK        = \"asr\"\n",
    "USE_PNC     = True\n",
    "BATCH_SIZE  = 16\n",
    "\n",
    "MIN_DUR, MAX_DUR = 1.0, 35.0\n",
    "CER_MAX, WER_MAX = 0.15, 0.50\n",
    "Q_CORE, Q_HARD   = 0.60, 0.95\n",
    "\n",
    "LINKS = [\n",
    "    \"bond005/taiga_speech_v2\",\n",
    "    \"bond005/rulibrispeech\",\n",
    "    \"bond005/podlodka_speech\",\n",
    "    \"bond005/audioset-nonspeech\",\n",
    "    \"mozilla-foundation/common_voice_17_0\",\n",
    "    \"google/fleurs\",\n",
    "]\n",
    "\n",
    "SPLITS = [\"train\", \"validation\", \"test\"]\n",
    "RUPAT  = re.compile(r\"(^|[-_])ru([-_]|$)|russian\", re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка базовых зависимостей (без переустановки torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "def pip_install(args):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-U\", *args]\n",
    "    print(\"+\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "base = [\n",
    "    \"datasets[audio]>=2.20.0\",\n",
    "    \"huggingface_hub>=0.24\",\n",
    "    \"soundfile>=0.12\",\n",
    "    \"pydub>=0.25\",\n",
    "    \"jiwer>=3.0.0\",\n",
    "    \"pandas>=2.2.0\",\n",
    "    \"tqdm>=4.66\"\n",
    "]\n",
    "pip_install(base)\n",
    "\n",
    "print(\"OK: базовые пакеты установлены\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX: стек NumPy/SciPy/Lightning/TorchMetrics + установка NeMo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "def run(cmd):\n",
    "    print(\"+\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"pip>=24.2\", \"setuptools>=75\", \"wheel>=0.44\"])\n",
    "\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"-U\",\n",
    "     \"numpy>=2.2,<2.4\",\n",
    "     \"scipy>=1.14,<1.17\",\n",
    "     \"torchmetrics>=1.5.2\",\n",
    "     \"lightning>=2.5.2,<2.6\"\n",
    "])\n",
    "\n",
    "# Install NeMo if missing\n",
    "try:\n",
    "    from nemo.collections.asr.models import ASRModel\n",
    "    import nemo\n",
    "    print(\"NeMo already present:\", nemo.__version__)\n",
    "except Exception:\n",
    "    run([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"nemo_toolkit[asr]==2.4.0\"])\n",
    "    from nemo.collections.asr.models import ASRModel\n",
    "    import nemo\n",
    "\n",
    "import numpy, scipy, lightning, torchmetrics, nemo as _nemo\n",
    "print(\"NumPy      :\", numpy.__version__)\n",
    "print(\"SciPy      :\", scipy.__version__)\n",
    "print(\"Lightning  :\", lightning.__version__)\n",
    "print(\"TorchMetrics:\", torchmetrics.__version__)\n",
    "print(\"NeMo       :\", _nemo.__version__)\n",
    "\n",
    "# shim for `import numpy.char` if some dep expects it\n",
    "import types, sys as _sys\n",
    "if \"numpy.char\" not in _sys.modules:\n",
    "    import numpy as _np\n",
    "    _mod = types.ModuleType(\"numpy.char\")\n",
    "    for k in dir(_np.char):\n",
    "        setattr(_mod, k, getattr(_np.char, k))\n",
    "    _sys.modules[\"numpy.char\"] = _mod\n",
    "    print(\"[shim] injected numpy.char module\")\n",
    "\n",
    "print(\"OK: NeMo стек готов\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хелперы: WAV + JSONL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, hashlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset, Audio\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sha1_name(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def ensure_wav_mono16k(data, sr):\n",
    "    # returns np.float32 mono at 16k sampling rate\n",
    "    import numpy as np\n",
    "    if getattr(data, \"ndim\", 1) > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    if sr != 16000:\n",
    "        try:\n",
    "            import librosa\n",
    "            data = librosa.resample(y=data, orig_sr=sr, target_sr=16000)\n",
    "            sr = 16000\n",
    "        except Exception:\n",
    "            raise RuntimeError(\"Need resample to 16k but librosa not available\")\n",
    "    return data, 16000\n",
    "\n",
    "def save_wav(path: Path, data, sr: int):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sf.write(str(path), data, sr, subtype=\"PCM_16\", format=\"WAV\")\n",
    "\n",
    "def prepare_hf_dataset_to_wav(repo: str, split: str, out_root: Path, lang_regex, hf_token=None):\n",
    "    kwargs = {}\n",
    "    if hf_token:\n",
    "        kwargs[\"token\"] = hf_token\n",
    "    try:\n",
    "        ds = load_dataset(repo, split=split, streaming=False, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {repo}:{split} → {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        ds = ds.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    name = f\"{repo.replace('/','___')}_{split}\"\n",
    "    out_dir = out_root / name\n",
    "    audio_dir = out_dir / \"audio\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    manifest = out_dir / \"manifest.jsonl\"\n",
    "\n",
    "    kept = 0\n",
    "    with manifest.open(\"w\", encoding=\"utf-8\") as fo:\n",
    "        for i, row in enumerate(tqdm(ds, desc=f\"{repo}:{split}\")):\n",
    "            text = None\n",
    "            for key in [\"text\",\"sentence\",\"transcript\",\"transcription\",\"label\",\"target\"]:\n",
    "                if key in row and row[key]:\n",
    "                    text = str(row[key]).strip()\n",
    "                    break\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            lang_val = None\n",
    "            for lkey in [\"lang\",\"language\",\"source_lang\",\"locale\"]:\n",
    "                if lkey in row and row[lkey]:\n",
    "                    lang_val = str(row[lkey]).lower()\n",
    "                    break\n",
    "            if lang_val and not lang_regex.search(lang_val):\n",
    "                continue\n",
    "\n",
    "            audio = row.get(\"audio\")\n",
    "            if not audio:\n",
    "                continue\n",
    "\n",
    "            arr = audio[\"array\"]\n",
    "            sr  = audio[\"sampling_rate\"]\n",
    "            try:\n",
    "                arr, sr = ensure_wav_mono16k(np.asarray(arr), int(sr))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            dur = float(len(arr) / sr)\n",
    "            if not (MIN_DUR <= dur <= MAX_DUR):\n",
    "                continue\n",
    "\n",
    "            wav_path = audio_dir / f\"{sha1_name(name+'_'+str(i))}.wav\"\n",
    "            save_wav(wav_path, arr, sr)\n",
    "\n",
    "            item = {\"audio_filepath\": str(wav_path), \"text\": text, \"duration\": dur}\n",
    "            fo.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "            kept += 1\n",
    "\n",
    "    print(f\"[OK] {name}: {kept} записей\")\n",
    "    return {\"name\": name, \"manifest\": str(manifest), \"dir\": str(out_dir), \"kept\": kept}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка датасетов (WAV + JSONL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\") or os.environ.get(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "\n",
    "prepared = []\n",
    "for repo in LINKS:\n",
    "    for split in SPLITS:\n",
    "        meta = prepare_hf_dataset_to_wav(repo, split, DATA_DIR, RUPAT, hf_token=HF_TOKEN)\n",
    "        if meta and meta[\"kept\"] > 0:\n",
    "            prepared.append(meta)\n",
    "\n",
    "print(\"Prepared:\", len(prepared), \"splits\")\n",
    "for m in prepared[:5]:\n",
    "    print(\" -\", m[\"name\"], \"→\", m[\"kept\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс Canary + фильтрация + экспорт core/hard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "from jiwer import wer, cer\n",
    "from pathlib import Path\n",
    "from nemo.collections.asr.models import ASRModel\n",
    "\n",
    "def load_canary(model_id: str, nemo_path: str | None):\n",
    "    if nemo_path:\n",
    "        return ASRModel.restore_from(nemo_path, map_location=\"cuda\").eval()\n",
    "    return ASRModel.from_pretrained(model_name=model_id).eval()\n",
    "\n",
    "model = load_canary(MODEL_ID, NEMO_PATH)\n",
    "\n",
    "def transcribe_paths(model, paths, batch_size, source_lang, target_lang, task, pnc):\n",
    "    results = {}\n",
    "    bs = max(1, int(batch_size))\n",
    "    import torch, gc\n",
    "    for i in range(0, len(paths), bs):\n",
    "        batch = paths[i:i+bs]\n",
    "        hyps = model.transcribe(batch, batch_size=bs,\n",
    "                                source_lang=source_lang, target_lang=target_lang,\n",
    "                                task=task, pnc=pnc)\n",
    "        for p, h in zip(batch, hyps):\n",
    "            if isinstance(h, str): results[p] = h\n",
    "            elif isinstance(h, dict): results[p] = h.get(\"text\") or h.get(\"pred_text\") or str(h)\n",
    "            else: results[p] = str(h)\n",
    "        try:\n",
    "            torch.cuda.empty_cache(); torch.cuda.ipc_collect()\n",
    "        except Exception:\n",
    "            pass\n",
    "        gc.collect()\n",
    "    return results\n",
    "\n",
    "def compute_metrics(items, preds):\n",
    "    out = []\n",
    "    for it in items:\n",
    "        a = it[\"audio_filepath\"]; ref = it[\"text\"]; d = it[\"duration\"]\n",
    "        hyp = preds.get(a, \"\")\n",
    "        if not hyp: \n",
    "            continue\n",
    "        out.append({\n",
    "            \"audio\": a, \"ref\": ref, \"hyp\": hyp, \"dur\": float(d),\n",
    "            \"wer\": float(wer(ref, hyp)), \"cer\": float(cer(ref, hyp))\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def split_by_quantiles(items, q_core, q_hard):\n",
    "    if not items: \n",
    "        return [], [], {\"q_core_val\":0.0,\"q_hard_val\":0.0}\n",
    "    s = pd.Series([it[\"wer\"] for it in items], dtype=float)\n",
    "    q_core_val = float(s.quantile(q_core)); q_hard_val = float(s.quantile(q_hard))\n",
    "    core = [it for it in items if it[\"wer\"] <= q_core_val]\n",
    "    hard = [it for it in items if (it[\"wer\"] > q_core_val) and (it[\"wer\"] <= q_hard_val)]\n",
    "    return core, hard, {\"q_core_val\": q_core_val, \"q_hard_val\": q_hard_val}\n",
    "\n",
    "def export_bucket(bucket_name: str, items, ds_dir: Path):\n",
    "    out_dir = ds_dir / bucket_name\n",
    "    audio_dir = out_dir / \"audio\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True); audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    manifest = out_dir / \"manifest.jsonl\"\n",
    "    kept = 0\n",
    "    with manifest.open(\"w\", encoding=\"utf-8\") as fo:\n",
    "        for it in items:\n",
    "            row = {\"audio_filepath\": it[\"audio\"], \"text\": it[\"ref\"], \"pred_text\": it[\"hyp\"],\n",
    "                   \"wer\": it[\"wer\"], \"cer\": it[\"cer\"], \"duration\": it[\"dur\"]}\n",
    "            fo.write(json.dumps(row, ensure_ascii=False) + \"\\n\"); kept += 1\n",
    "    return kept, manifest\n",
    "\n",
    "summaries = []\n",
    "\n",
    "for meta in prepared:\n",
    "    man_path = Path(meta[\"manifest\"])\n",
    "    ds_dir   = Path(meta[\"dir\"])\n",
    "    with man_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        items = [json.loads(x) for x in f]\n",
    "\n",
    "    uniq_paths = list({it[\"audio_filepath\"] for it in items})\n",
    "    preds = transcribe_paths(model, uniq_paths, BATCH_SIZE, SOURCE_LANG, TARGET_LANG, TASK, USE_PNC)\n",
    "\n",
    "    metrics_all = compute_metrics(items, preds)\n",
    "    pool = [m for m in metrics_all if (m[\"cer\"] <= CER_MAX and m[\"wer\"] <= WER_MAX)]\n",
    "    core_items, hard_items, qvals = split_by_quantiles(pool, Q_CORE, Q_HARD)\n",
    "\n",
    "    hard_kept, hard_manifest = export_bucket(\"hard\", hard_items, ds_dir)\n",
    "    core_kept, core_manifest = export_bucket(\"core\", core_items, ds_dir)\n",
    "\n",
    "    summary = {\n",
    "        \"dataset\": meta[\"name\"],\n",
    "        \"total\": len(items), \"pool\": len(pool),\n",
    "        \"q_core\": Q_CORE, \"q_hard\": Q_HARD,\n",
    "        \"q_core_val\": qvals[\"q_core_val\"], \"q_hard_val\": qvals[\"q_hard_val\"],\n",
    "        \"core_selected\": len(core_items), \"core_saved\": core_kept, \"core_manifest\": str(core_manifest),\n",
    "        \"hard_selected\": len(hard_items), \"hard_saved\": hard_kept, \"hard_manifest\": str(hard_manifest),\n",
    "        \"params\": {\"min_dur\": MIN_DUR, \"max_dur\": MAX_DUR, \"cer_max\": CER_MAX, \"wer_max\": WER_MAX,\n",
    "                   \"task\": TASK, \"pnc\": USE_PNC, \"source_lang\": SOURCE_LANG, \"target_lang\": TARGET_LANG},\n",
    "    }\n",
    "    with (ds_dir / \"summary.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    summaries.append(summary)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(summaries)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
